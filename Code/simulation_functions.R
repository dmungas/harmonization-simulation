# extractDiffMatrix is used by equateSim and not called directly
extractDiffMatrix <- function(pars) {
  diff1 <- pars[grepl("d+", pars$name), c("item", "name", "value")]
  diff1$item <- as.character(diff1$item)
  diffsum <- diff1 %>% group_by(item) %>% summarise(ncat = sum(!is.na(item)))
  diff <- matrix(nrow = nrow(diffsum), ncol = max(diffsum$ncat))
  for (j in 1:nrow(diffsum)) {
    vals <- diff1[diff1$item %in% diffsum[j, "item"], "value"]
    if (length(vals) < max(diffsum$ncat)) {
      for (i in (length(vals) + 1):max(diffsum$ncat)) {
        vals[i] <- NA
      }
    }
    diff[j, ] <- vals
  }
  return(diff)
}


# equateSim is a function the uses R mirt item response theory (IRT) methods
# to: 1) simulate item level datasets based on item parameters, 2) perform IRT
# calibrations on the simulated datasets, 3) estimate ability scores for each
# person in the simulated datasets, and 4) compute metrics to quantify the
# correspondence between the estimated ability from the simulated datasets and the
# true ability that was used to generate the simulations. Metrics include the
# root mean square error (RMSE), the mean of the estimated ability scores,
# the standard deviation of the estimated ability scores, and, optionally,
# the reliability of the estimated ability scores as measured by the agreement
# (Pearson's r or intra-class correlation) between the estimated ability scores
# and the data-generating theta values for each case. Multiple simulations
# of the same set of simulated true ability values can be generated (n_rep_theta).
#   This function simulates two groups that can differ in mean and standard
# deviation of simulated true ability, and different items can be used for each
# group as long as there is at least one common, linking item.
#
# Parameters:
#   seed - random seed for simulations (default=NULL)
#   grp_mean - true ability means of the two groups (default=c(0.5,-0.5))
#   grp_sd - true ability standard deviations of the two groups (default=c(1,1))
#   ref_grp - which group is used as the reference? 0 = no reference group, 1 = group 1, 2 = group 2
#   n_rep - number of simulated samples of true ability values (default=100)
#   n_rep_theta - number of repetitions of each simulated sample of true ability
#     values (default=1)
#   n_samp1 - sample size of group 1 in each simulation (default=500)
#   n_samp2 - sample size of group 2 in each simulation (default=500)
#   pars - mirt item parameters file (default=mcal_par)
#     A parameter file can be generated by:
#       mcal_par <- mirt(df,mdl,pars='values') where df is a dataframe with
#         item response data and mdl is a mirt model object. The returned file
#         (mcal_par in this example) can be edited to change item parameters.
#   n_rep - number of simulated samples of true ability values (default=100)
#   itms1 - list of items available for group 1 (default=item_list_1)
#   itms2 - list of items available for group 2 (default=item_list_2)
#   fsc_method - mirt method for calculating estimated ability values
#     (default="EAP")
#   mod_res_obj - mirt model results object from mirt analysis. This must
#     be from the same mirt model as pars.
#   save_sims - option to output simulated datasets (default=FALSE)
#   verbose - option to print (TRUE) or suppress (FALSE) messages (default = FALSE)
#   save_log - option to save a log of verbose output instead of printing to screen (default = TRUE)
#   log_file - name of log file to be saved. Default is paste0("technical_output_log_", format(Sys.time(), "%Y-%m-%d_%I-%M-%p"), ".txt")
#   prog_bar - option to show a progress bar on screen instead of verbose messages (default = TRUE)
#   rel - option to calculate reliability statistics for individual ability estimates (default = TRUE)
#   man_override - list of parameters and their values to manually override when performing the simulations. The default is NULL.
#     Three parameters must be specified in the list. These are:
#       1. iname - the name of the item(s) whose parameters will be fixed (character vector)
#       2. parameter - the name of the parameter to be fixed (character vector)
#         Options include:
#           "a1" - item discrimination
#           "d" - item easiness (the default in mirt) for a dichotomous indicator
#           "d1", "d2", ... "dk", item easiness (the default in mirt) thresholds where k is the number of thresholds for a polytomous item.
#           "b" - item difficulty (converted to easiness by this script for use in mirt) for a dichotomous indicator
#           "b1", "b2", ... "bk", item difficulty (converted to easiness by this script for use in mirt) thresholds where k is the number of thresholds for a polytomous item.
#       3. val - the numeric value of the parameter(s) to be fixed (numeric)
#     Example usage is as follows:
#         man_override = list(iname = c("UDAY", "UMON"),
#                           parameter = c("b", "b"),
#                           val = c(0, 1.928))
#   std_sample - option to standardize the harmonized factor scores with scaling based on the empirical sample data (default = FALSE, which uses population-based scaling)
#   std_ref - if std_sample = TRUE, this sets the reference group for scaling of the standardized factor scores.
#       Options are:
#           0 for combined sample
#           1 for group 1
#           2 for group 2
#           NULL (default)

# equateSim returns a list with 2 elements:
# 1. "summary" - a dataframe that has summary statistics (rmse, mean
# estimated ability, sd estimated ability, and, optionally, Pearson's r and ICC(C,1) reliability statistics)
# for each group and each simulated
# sample of true abilities (n_rep). These statistics are produced for raw
# estimated abilities and for estimated abilities on a metric transformed to
# match the true ability metric (default) or the metric scaled according
# to a reference sample's mean and standard deviation.
# 2. "datasets" (if save_sims=TRUE) - a long format dataframe that includes original and estimated
# theta scores, group assignment, sample number, and rep_theta number

equateSim <- function(seed = NULL,
                      grp_mean = c(0.5,-0.5),
                      grp_sd = c(1, 1),
                      ref_grp = 1,
                      n_samp1 = 500,
                      n_samp2 = 500,
                      n_rep_theta = 1,
                      pars = mcal_pars,
                      n_rep = 100,
                      itms1 = item_list_1,
                      itms2 = item_list_2,
                      fsc_method = "EAP",
                      mod_res_obj = NULL,
                      save_sims = FALSE,
                      verbose = FALSE,
                      save_log = TRUE,
                      log_file = paste0("technical_output_log_",
                                        format(Sys.time(), "%Y-%m-%d_%I-%M-%p"),
                                        ".txt"),
                      prog_bar = TRUE,
                      rel = TRUE,
                      man_override = NULL,
                      std_sample = FALSE,
                      std_ref = NULL) {
  
  ### Begin initialize display settings
  if (prog_bar) {
    library(progress)
    if (verbose & !save_log) {
      warning(
        "Progress bar cannot be displayed if verbose == TRUE. A log file will be created to store verbose output."
      )
      save_log <- TRUE
    }
    pb <- progress_bar$new(
      format = "  Simulating data [:bar] :current of :total (:percent) elapsed: :elapsed eta: :eta",
      total = n_rep,
      clear = FALSE,
      width = 80
    )
  }
  ### End initialize display settings
  
  ### Begin initialize logging of technical output
  if (save_log) {
    verbose <- TRUE
    options(max.print = 9999)
    sink(log_file)
    print(sys.call(which = 0L)) # Prints the function call
    print(mget(ls()[!(ls() == "pb")])) # prints the arguments passed to the equateSim function
  }
  ### End initialize logging of technical output
  
  ### Begin load required packages
  require(dplyr)
  require(tidyr)
  require(mirt)
  require(stringr)
  if (rel) require(irr) # load irr package if reliability statistics are requested.
  ### End load required packages
  
  ### Begin check to ensure objects passed to function are correctly specified.
  if (any(!is.character(itms1),!is.character(itms2))) {
    if (save_log) {
      print("Error: itms1 and itms2 should be character vectors.")
      sink()
    }
    stop("itms1 and itms2 should be character vectors.")
  } else if (!(ref_grp %in% 0:2)) {
    if (save_log) {
      print(
        "Error: Incorrectly specified reference group. ref_grp should be 0 for no reference group, 1 for group 1, or 2 for group 2."
      )
      sink()
    }
    stop(
      "Incorrectly specified reference group. ref_grp should be 0 for no reference group, 1 for group 1, or 2 for group 2."
    )
  } else {
    ### End check to ensure objects passed to function are correctly specified.
    
    ### Begin initialize items, parameters, and model syntax
    n_itm <- length(union(itms1, itms2))
    link_itms <- dplyr::intersect(itms1, itms2)
    if (save_log) {
      cat("\n Group 1 Items: ", itms1)
      cat("\n Group 2 Items: ", itms2)
      cat("\n Linking Items: ", link_itms, "\n\n")
    }
    diff <- extractDiffMatrix(pars)
    disc <- pars[pars$name == "a1", "value"]
    itemtype <- as.character(pars[pars$name == "a1", "class"])
    model <- mirt.model(paste0("cog = 1-", n_itm))
    
    # If manual override is requested, this checks to see whether user-inputted data
    # is in the form of difficulty (b) parameters.
    # If so, this converts them to easiness (d) parameters for use in mirt
    # The conversion formula used is d = b/-a
    if (!is.null(man_override)) {
      for (p in 1:length(man_override$iname)) {
        # Convert b to d
        if (str_detect(man_override$parameter[p], "b")) {
          man_override$parameter[p] <- gsub("b", "d", man_override$parameter[p])
          man_override$val[p] <- man_override$val[p] / -coef(mod_res_obj)[[man_override$iname[p]]][1]
        }
      }
    }
    ### End initialize items, parameters, and model syntax
    
    ### Begin simulating, estimating factor scores, and generating summary data
    set.seed(seed)
    j <- 0
    while (j < n_rep) {
      j <- j + 1
      startj <- j # keep track of where j starts
      time <- Sys.time() # keep track of time simulation began
      theta1 <- data.frame(rnorm(n_samp1, grp_mean[1], grp_sd[1])) # simulate group 1 data
      names(theta1) <- "theta1"
      theta1$group <- 1
      theta2 <- data.frame(rnorm(n_samp2, grp_mean[2], grp_sd[2])) # simulate group 2 data
      names(theta2) <- "theta1"
      theta2$group <- 2
      theta1 <- rbind(theta1, theta2) # combine groups 1 and 2
      
      ### Begin data simulation
      ds <- list() # ds is used to store each replicate of a simulated data set for a given theta 
      # (by default, only one replicate per theta (n_rep_theta) is simulated, so unless the user overrides this 
      # setting, the length of ds will be 1).
      for (i in 1:n_rep_theta) {
        if (is.null(mod_res_obj)) {
          
          # ds2 contains the data simulated according to the specified parameters
          # Here, ds2 is created when no mod_res_obj is provided by the user.
          # Item parameters are taken from the mirt item parameters object passed to the pars argument
          ds2 <- data.frame(simdata(a = disc,
                                    d = diff,
                                    N = n_samp1 + n_samp2,
                                    Theta = as.matrix(theta1$theta1),
                                    itemtype = itemtype))
        } else {
          if (!is.null(man_override)) {
            # If manual override of at least one item parameter is requested, this 
            # replaces the existing item parameters passed as part of the mod_res_obj
            # object with the user-specified parameters
            
            # Get the parameters from mod_res_obj
            sim_pars <- coef(mod_res_obj, simplify = TRUE)$items %>%
              data.frame() %>%
              mutate(item = rownames(.)) %>%
              pivot_longer(cols = names(dplyr::select(.,-item)))
            
            # For each user-specified parameter to be manually overridden, replace
            # the mod_res_obj parameters with the user-specified values
            for (p in 1:length(man_override$iname)) {
              sim_pars$value[sim_pars$item == man_override$iname[p] &
                               sim_pars$name == man_override$parameter[p]] <- man_override$val[p]
            }
            
            # Reshape easiness parameter data so the object matches the matrix format required by mirt
            sim_pars_d <- as_tibble(matrix(sim_pars$value[sim_pars$name %in% str_sort(unique(str_extract(pars$name, "^d[1-9]*")),
                                                                                      na_last = NA)],
                                           nrow = n_itm,
                                           byrow = TRUE)) %>%
              mutate(V1 = coalesce(V1, V2)) %>%
              dplyr::select(-V2) %>%
              data.matrix()
            
            # ds2 contains the data simulated according to the specified parameters
            # Here, ds2 is created when mod_res_obj is provided by the user AND 
            # when manual override of at least one parameter is requested.
            # These item parameters are taken from the mod_res_obj object 
            # unless otherwise specified ing the man_override argument
            ds2 <- data.frame(simdata(
              a = sim_pars$value[sim_pars$name == "a1"],
              d = sim_pars_d,
              itemtype = itemtype,
              N = n_samp1 + n_samp2,
              Theta = as.matrix(theta1$theta1)))
          } else {
            
            # ds2 contains the data simulated according to the specified parameters
            # Here, ds2 is created when mod_res_obj is provided by the user AND 
            # when manual override of at least one parameter is NOT requested.
            # These item parameters are taken from the mod_res_obj object 
            ds2 <- data.frame(simdata(
              model = mod_res_obj,
              N = n_samp1 + n_samp2,
              Theta = as.matrix(theta1$theta1)
            ))
          }
        }

        names(ds2) <- unique(pars[!pars$item == "GROUP", "item"])
        ds2 <- cbind(theta1, ds2)
        
        # For each group, create missing data for items not administered to that group
        for (group in 1:2) {
          if (group == 1) {
            ds2[ds2$group == 1, !names(ds2) %in% c("theta1", "group", itms1)] <- NA
          } else {
            ds2[ds2$group == 2, !names(ds2) %in% c("theta1", "group", itms2)] <- NA
          }

        }
        ds[[i]] <- ds2
      }
      ### End data simulation
      
      ### Begin parameter estimation using simulated data
      #### First, estimate the item parameters in the reference group only (metric fixed to N(0, 1))
      #### Second, fix the item parameters obtained from step 1 and re-run the model in the full sample, 
      ##### freely estimating the latent variable mean and variance.
      ##### This scales the metric according to the reference group.
      #### Third, fix all item parameter estimates, as well as the latent variable mean and standard deviation,
      ##### and run a model with no free parameters. 
      ##### This model with no free parameters will be used to generate factor scores in the full sample.
      sim_summ <- list()
      dataset <- list()
      for (i in 1:length(ds)) {
        # capture errors due to not all response option occurring in simulated dataset
        pars1 <- tryCatch({
          # This gets the parameter structure for the full data set and saves it as pars1
          # Later, this parameter structure is modified when fixing parameters to the
          # values derived from the reference group (if applicable)
          # This does not do any parameter estimation.
          mirt(
            ds[[i]][, 3:(n_itm + 2)],
            model = model,
            pars = 'values',
            verbose = verbose,
            technical = list(
              warn = all(!prog_bar, verbose) ,
              message = all(!prog_bar, verbose)
            )
          )
        }, warning = function(w) {
          return("warning")
        }, error = function(e) {
          return("error")
        })
        
        # t1 <- dplyr::select(ds[[i]], names(ds[[i]])[3:(n_itm+2)])
        
        pars2 <- tryCatch({
          # This gets the parameter structure for the model when applied to the reference group (if applicable)
          # and saves it as pars2
          if (ref_grp == 0) {
            # No reference group (full sample)
            # This does not do any parameter estimation.
            mirt(
              dplyr::select(ds[[i]], names(ds[[i]])[3:(n_itm + 2)]),
              model = model,
              pars = 'values',
              verbose = verbose,
              technical = list(
                warn = all(!prog_bar, verbose),
                message = all(!prog_bar, verbose)
              )
            )
          } else if (ref_grp == 1) {
            # Reference group 1
            # This does not do any parameter estimation.
            mirt(
              dplyr::select(filter(ds[[i]], group == ref_grp), all_of(itms1)),
              model = mirt.model(paste0("cog = 1-", length(itms1))),
              pars = 'values',
              verbose = verbose,
              technical = list(
                warn = all(!prog_bar, verbose),
                message = all(!prog_bar, verbose)
              )
            )
          }  else if (ref_grp == 2) {
            # Reference group 2
            # This does not do any parameter estimation.
            mirt(
              dplyr::select(filter(ds[[i]], group == ref_grp), all_of(itms2)),
              model = mirt.model(paste0("cog = 1-", length(itms2))),
              pars = 'values',
              verbose = verbose,
              technical = list(
                warn = all(!prog_bar, verbose),
                message = all(!prog_bar, verbose)
              )
            )
          } else {
            stop(
              "Incorrectly specified reference group. ref_grp should be 0 for no reference group, 1 for group 1, or 2 for group 2."
            )
          }
        }, warning = function(w) {
          return("warning")
        }, error = function(e) {
          return("error")
        })
        
        if (is.data.frame(pars1) & is.data.frame(pars2)) {
          if (verbose) {
            cat("check 1 - pars1 and pars2 are dataframes\n")
          }
          if (nrow(pars1[pars1$item %in% link_itms, ]) ==
              nrow(pars2[pars2$item %in% link_itms, ])) {
            if (verbose) {
              cat(
                "check 2 - pars1 and pars2 linking items have the same number of parameters\n"
              )
            }
            # If a reference group is selected, this runs the model only on the simulated reference group data/items
            # to obtain difficulty and discrimination parameter estimates for the linking items
            # that are later applied as constraints in the full sample.
            if (ref_grp == 1) {
              # Reference group 1
              # This does parameter estimation in group 1 only.
              # The metric is set to the default N(0, 1). No other parameters are fixed here.
              mcal_rg <-
                mirt(
                  dplyr::select(filter(ds[[i]], group == ref_grp), all_of(itms1)),
                  model = mirt.model(paste0("cog = 1-", length(
                    itms1
                  ))),
                  pars = pars2,
                  verbose = verbose,
                  technical = list(
                    warn = all(!prog_bar, verbose),
                    message = all(!prog_bar, verbose)
                  )
                )
              if (verbose) {
                cat("calibration reference group = 1\n")
              }
            } else if (ref_grp == 2) {
              # Reference group 2
              # This does parameter estimation in group 2 only.
              # The metric is set to the default N(0, 1). No other parameters are fixed here.
              mcal_rg <-
                mirt(
                  dplyr::select(filter(ds[[i]], group == ref_grp), all_of(itms2)),
                  model = mirt.model(paste0("cog = 1-", length(
                    itms2
                  ))),
                  pars = pars2,
                  verbose = verbose,
                  technical = list(
                    warn = all(!prog_bar, verbose),
                    message = all(!prog_bar, verbose)
                  )
                )
              if (verbose) {
                cat("calibration reference group = 2\n")
              }
            } else if (ref_grp != 0) {
              stop(
                "Incorrectly specified reference group. ref_grp should be 0 for no reference group, 1 for group 1, or 2 for group 2."
              )
            }
            
            
            if (ref_grp %in% 1:2) {
              # If parameter estimates were obtained for one of the reference groups,
              # constrain the linking item parameters here before estimating the models in the combined sample.
              
              for (itm in link_itms) {
                mcal_itm <- data.frame(coef(
                  mcal_rg,
                  IRTpars = FALSE,
                  simplify = TRUE
                )$items)[itm, ]
                
                if (!is.na(mcal_itm$d)) {
                  nthresh <- 1
                } else {
                  nthresh <- sum(!is.na(dplyr::select(
                    mcal_itm, starts_with("d")
                  )))
                }
                
                pars1$value[pars1$name == "a1" &
                              pars1$item %in% itm] <- mcal_itm[, "a1"]
                pars1$est[pars1$name == "a1" &
                            pars1$item %in% itm] <- FALSE
                
                for (threshn in 1:nthresh) {
                  if (nthresh == 1) {
                    pars1$value[pars1$name == "d" &
                                  pars1$item %in% itm] <-
                      mcal_itm[, "d"]
                    pars1$est[pars1$name == "d" &
                                pars1$item %in% itm] <- FALSE
                    
                  } else if (nthresh > 1) {
                    pars1$value[pars1$name == paste0("d", threshn) &
                                  pars1$item %in% itm] <-
                      mcal_itm[, paste0("d", threshn)]
                    pars1$est[pars1$name == paste0("d", threshn) &
                                pars1$item %in% itm] <- FALSE
                    
                  }
                }
              }
            }
            
            if (ref_grp %in% 1:2) {
              # If a reference group is used (item parameters are constrained), freely estimate the latent variable mean and variance.
              # This sets the metric based on the fixed parameter estimates.
              pars1$est[pars1$name == "MEAN_1"] <- TRUE
              pars1$est[pars1$name == "COV_11"] <- TRUE
              if (verbose) {
                cat(
                  "\n\nParameter table after fixing to values of chosen reference group\n\n"
                )
                print(pars1)
                cat("\n\n")
              }
            }
            
            # Now run the mirt model with either the linking items unconstrained (no reference group)
            # or constrained (to the values estimated in the reference group) models
            mcal <-
              mirt(
                ds[[i]][, 3:(n_itm + 2)],
                model = model,
                pars = pars1,
                verbose = verbose,
                technical = list(
                  warn = all(!prog_bar, verbose),
                  message = all(!prog_bar, verbose)
                )
              )
            
            ### End parameter estimation using simulated data
            
            ### Begin generating individual ability estimates (factor scores)
            # Then fix all of the parameters to their estimates and use this fully constrained model to estimate factor scores.
            
            mcal_pars <- data.frame(coef(mcal, IRTpars = FALSE,
                                         simplify = TRUE)$items) %>%
              mutate(item = rownames(.)) %>%
              pivot_longer(
                cols = -item,
                names_to = "name",
                values_to = "value",
                values_drop_na = TRUE
              )
            pars3 <- pars1
            pars3$value[1:nrow(mcal_pars)] <- mcal_pars$value
            pars3$value[pars3$name == "MEAN_1"] <-
              0 #coef(mcal)$GroupPars[1]
            # third option - free estimates of M & SD
            pars3$value[pars3$name == "COV_11"] <-
              1 #coef(mcal)$GroupPars[2]
            pars3$est <- FALSE
            
            fcmod <-
              mirt(
                ds[[i]][, 3:(n_itm + 2)],
                model = model,
                pars = pars3,
                verbose = verbose,
                technical = list(
                  warn = all(!prog_bar, verbose),
                  message = all(!prog_bar, verbose)
                )
              )
            
            if (verbose) {
              cat("calibration - final\n")
            }
            
            
            fsc <-
              data.frame(fscores(fcmod, full.scores = TRUE, method = fsc_method))
            names(fsc) <- "ability_est"
            t6 <- cbind(ds[[i]], fsc)
            # names(t6) <- sub("F1","ability_est",names(t6))
            names(t6) <- sub("theta1", "ability", names(t6))
            
            t6$ability_est <-
              ifelse(t6$ability_est %in% c(Inf, -Inf),
                     NA,
                     t6$ability_est)
            ### End generating individual ability estimates (factor scores)
            
            ### Begin standardizing factor scores and calculating unstandardized and standardized residuals
            t6$resid <- t6$ability_est - t6$ability
            
            if (std_sample) {
              # Standardized factor scores based on sample estimates
              if (std_ref == 0) {
                # standardize factor scores based on M and SD of full sample
                t6$abil_est_st <-
                  (t6$ability_est - mean(t6$ability_est, na.rm = TRUE)) / sd(t6$ability_est)
              } else {
                # standardize factor scores based on M and SD of chosen subgroup
                t6$abil_est_st <-
                  (t6$ability_est - mean(t6$ability_est[t6$group == std_ref], na.rm = TRUE)) /
                  sd(t6$ability_est[t6$group == std_ref])
              }
            } else {
              # Standardized factor scores informed by population parameters
              t6$abil_est_st <-
                (t6$ability_est - mean(t6$ability_est, na.rm = TRUE)) *
                (sd(t6$ability) / sd(t6$ability_est, na.rm = TRUE)) +
                mean(t6$ability) # linear equating to true ability metric
            }
            
            t6$resid_st <- t6$abil_est_st - t6$ability
            ### End standardizing factor scores and calculating unstandardized and standardized residuals
            
            t6$sample <- j
            t6$rep_theta <- i
            
            
            sim_summ[[i]] <-
              t6[, c("ability",
                     "ability_est",
                     "resid",
                     "abil_est_st",
                     "resid_st",
                     "group")]
            
            if (save_sims == TRUE) {
              if (j == 1 & i == 1) {
                sim_data <- t6
              } else {
                sim_data <- rbind(sim_data, t6)
              }
            }
          } else {
            if (verbose) {
              cat(
                "check 3 - pars1 and pars2 linking items have different numbers of parameters\n"
              )
            }
            j <- j - 1
          }
        } else {
          if (verbose) {
            cat("check 4 - pars1 or pars2 are not dataframes\n")
          }
          j <- j - 1
        }
      }
      ### This code block can be modified to output true ability, estimated
      #   ability, and simulated datasets
      # abil <- data.frame(matrix(ncol = length(sim_summ), nrow = 500))
      # abil_est <- data.frame(matrix(ncol = length(sim_summ), nrow = 500))
      # res <- data.frame(matrix(ncol = length(sim_summ), nrow = 500))
      if (j == startj) {
        # don't do these calculations and compile the data if j was reduced by 1
        # due to failed checks.
        stat <-
          data.frame(matrix(nrow = 12, ncol = length(sim_summ)))
        if (length(sim_summ) > 0) {
          for (i in 1:length(sim_summ)) {
            nm <- paste("dset_", i, sep = "")
            # abil[,i] <- sim_summ[[i]]$ability
            # names(abil)[i] <- nm
            # abil_est[,i] <- sim_summ[[i]]$abil_est_st
            # names(abil_est)[i] <- nm
            # res[,i] <- sim_summ[[i]]$resid_st
            # names(res)[i] <- nm
            df <- sim_summ[[i]]
            stat[1, i] <-
              sqrt(mean(df[df$group == 1, "resid"] ^ 2, na.rm = TRUE))
            stat[2, i] <-
              sqrt(mean(df[df$group == 2, "resid"] ^ 2, na.rm = TRUE))
            stat[3, i] <-
              sqrt(mean(df[df$group == 1, "resid_st"] ^ 2, na.rm = TRUE))
            stat[4, i] <-
              sqrt(mean(df[df$group == 2, "resid_st"] ^ 2, na.rm = TRUE))
            stat[5, i] <-
              mean(df[df$group == 1, "ability_est"], na.rm = TRUE)
            stat[6, i] <-
              mean(df[df$group == 2, "ability_est"], na.rm = TRUE)
            stat[7, i] <-
              mean(df[df$group == 1, "abil_est_st"], na.rm = TRUE)
            stat[8, i] <-
              mean(df[df$group == 2, "abil_est_st"], na.rm = TRUE)
            stat[9, i] <-
              sd(df[df$group == 1, "ability_est"], na.rm = TRUE)
            stat[10, i] <-
              sd(df[df$group == 2, "ability_est"], na.rm = TRUE)
            stat[11, i] <-
              sd(df[df$group == 1, "abil_est_st"], na.rm = TRUE)
            stat[12, i] <-
              sd(df[df$group == 2, "abil_est_st"], na.rm = TRUE)
            stat[13, i] <- sqrt(mean(df[, "resid"] ^ 2, na.rm = TRUE))
            stat[14, i] <- sqrt(mean(df[, "resid_st"] ^ 2, na.rm = TRUE))
            stat[15, i] <- mean(df[, "ability_est"], na.rm = TRUE)
            stat[16, i] <- mean(df[, "abil_est_st"], na.rm = TRUE)
            stat[17, i] <- sd(df[, "ability_est"], na.rm = TRUE)
            stat[18, i] <- sd(df[, "abil_est_st"], na.rm = TRUE)
            stat[19, i] <- grp_mean[1]
            stat[20, i] <- grp_mean[2]
            stat[21, i] <-
              weighted.mean(grp_mean, c(n_samp1, n_samp2))
            
            
            if (rel) {
              # Playing around with some different reliability statistics.
              stat[22, i] <-
                cor.test(df$ability[df$group == 1], df$ability_est[df$group == 1])$estimate
              stat[23, i] <-
                cor.test(df$ability[df$group == 2], df$ability_est[df$group == 2])$estimate
              stat[24, i] <-
                cor.test(df$ability, df$ability_est)$estimate
              stat[25, i] <-
                icc(df[df$group == 1, c("ability", "ability_est")],
                    model = "twoway",
                    type = "consistency",
                    unit = "single")$value # ICC(C,1)
              stat[26, i] <-
                icc(df[df$group == 2, c("ability", "ability_est")],
                    model = "twoway",
                    type = "consistency",
                    unit = "single")$value # ICC(C,1)
              stat[27, i] <-
                icc(df[c("ability", "ability_est")],
                    model = "twoway",
                    type = "consistency",
                    unit = "single")$value # ICC(C,1)
            }
            
            names(stat)[i] <- nm
            
            if (rel) {
              stat[c(1, 3, 5, 7, 9, 11, 19, 22, 25), "group"] <- 1
              stat[c(2, 4, 6, 8, 10, 12, 20, 23, 26), "group"] <- 2
              stat[c(13:18, 21, 24, 27), "group"] <- 0
              stat[c(1, 2, 5, 6, 9, 10, 13, 15, 17, 19:27), "type"] <-
                "raw"
              stat[c(3, 4, 7, 8, 11, 12, 14, 16, 18), "type"] <-
                "standardized"
              stat[c(1:4, 13:14), "statistic"] <- "rmse"
              stat[c(5:8, 15:16), "statistic"] <- "est_mean"
              stat[c(9:12, 17:18), "statistic"] <- "est_sd"
              stat[c(19:21), "statistic"] <- "theta"
              stat[c(22:24), "statistic"] <- "r_theta_est"
              stat[c(25:27), "statistic"] <- "ICC_C_1"
            } else {
              stat[c(1, 3, 5, 7, 9, 11, 19), "group"] <- 1
              stat[c(2, 4, 6, 8, 10, 12, 20), "group"] <- 2
              stat[c(13:18, 21), "group"] <- 0
              stat[c(1, 2, 5, 6, 9, 10, 13, 15, 17, 19:21), "type"] <-
                "raw"
              stat[c(3, 4, 7, 8, 11, 12, 14, 16, 18), "type"] <-
                "standardized"
              stat[c(1:4, 13:14), "statistic"] <- "rmse"
              stat[c(5:8, 15:16), "statistic"] <- "est_mean"
              stat[c(9:12, 17:18), "statistic"] <- "est_sd"
              stat[c(19:21), "statistic"] <- "theta"
            }
            
            stat$samp_num <- j
          } # end for i
        }
        if (j > 0) {
          if (j == 1) {
            stat_summ <- stat
          } else {
            stat_summ <- rbind(stat_summ, stat)
          }
        }
        if (verbose) {
          cat(
            paste(
              " ############################# Iteration - ",
              j,
              " of ",
              n_rep,
              ". Elapsed time: ",
              Sys.time() - time,
              "\n",
              sep = ""
            )
          )
        }
        if (prog_bar)
          pb$tick()
      }
    } # end while j
    if (n_rep_theta == 1) {
      stat_summ$avg <- stat_summ$dset_1
    } else {
      stat_summ$avg <- apply(stat_summ[, 1:n_rep], 1, mean)
    }
    sim_results <- list()
    sim_results[["summary"]] <- stat_summ
    if (save_sims == TRUE) {
      vnms <- c(
        "ability",
        "ability_est",
        "resid",
        "abil_est_st",
        "resid_st",
        "group",
        "sample",
        "rep_theta"
      )
      itnms <- names(sim_data[!names(sim_data) %in% vnms])
      sim_results[["datasets"]] <- sim_data[, c(vnms, itnms)]
    }
    if (save_log)
      sink()
    return(sim_results)
  }
}

# infoSim is a function that uses R mirt item response theory (IRT) methods
# to: 1) simulate an item level dataset based on item parameters, 2) perform an IRT
# calibrations on the simulated dataset, and 3) calculate test information values
# across a range of ability values. It estimates test information for two groups
# that can have different distributions of ability, and different items can be
# used for the two groups.

# Parameters:
#   seed - random seed for simulations (default=NULL)
#   grp_mean - true ability means of the two groups (default=c(0.5,-0.5))
#   grp_sd - true ability standard deviations of the two groups (default=c(1,1))
#   n_samp - sample size of each group in each simulation (default=500)
#   pars - mirt item parameters file (default=mcal_par)
#     A parameter file can be generated by:
# #       mcal_par <- mirt(df,mdl,pars='values') where df is a dataframe with
# #         item response data and mdl is a mirt model object. The returned file
# #         (mcal_par in this example) can be edited to change item parameters.
# #   itms1 - list of items available for group 1 (default=item_list_1)
# #   itms2 - list of items available for group 2 (default=item_list_2)
# This function returns a dataframe with ability values and corresponding test
# information values. This dataset can be use to graph a test information curve.

infoSim <- function(seed = NULL,
                    grp_mean = c(0.5, -0.5),
                    grp_sd = c(1, 1),
                    n_samp = 500,
                    pars = mcal_par,
                    itms1 = item_list_1,
                    itms2 = item_list_2) {
  diff <- pars[pars$name == "d", "value"]
  disc <- pars[pars$name == "a1", "value"]
  n_itm <- nrow(pars[pars$name == 'a1', ])
  links <- intersect(itms1, itms2)
  set.seed(seed)
  
  theta1 <- data.frame(rnorm(n_samp, grp_mean[1], grp_sd[1]))
  names(theta1) <- "theta1"
  theta1$group <- 1
  theta2 <- data.frame(rnorm(n_samp, grp_mean[2], grp_sd[2]))
  names(theta2) <- "theta1"
  theta2$group <- 2
  theta1 <- rbind(theta1, theta2)
  
  ds <-
    data.frame(simdata(
      disc,
      diff,
      n_samp,
      Theta = as.matrix(theta1$theta1),
      itemtype = '2PL'
    ))
  names(ds) <- unique(pars[!pars$item == "GROUP", "item"])
  ds <- cbind(theta1, ds)
  
  for (group in 1:2) {
    if (group == 1) {
      ds[ds$group == 1, !names(ds) %in% c("theta1", "group", itms1)] <- NA
    } else {
      ds[ds$group == 2, !names(ds) %in% c("theta1", "group", itms2)] <- NA
    }
  }
  
  pars1 <- pars[pars$item %in% c(itms1, "GROUP"), ]
  pars1$parnum <- 1:nrow(pars1)
  pars1[pars1$name == "d" & !pars1$item %in% links, "est"] <- TRUE
  pars1[pars1$name == "a1" & !pars1$item %in% links, "est"] <- TRUE
  
  pars2 <- pars[pars$item %in% c(itms2, "GROUP"), ]
  pars2$parnum <- 1:nrow(pars2)
  pars2[pars2$name == "d" & !pars2$item %in% links, "est"] <- TRUE
  pars2[pars2$name == "a1" & !pars2$item %in% links, "est"] <- TRUE
  
  n_itm_1 <- nrow(pars1[pars1$name == 'a1', ])
  n_itm_2 <- nrow(pars2[pars2$name == 'a1', ])
  
  mdl1 <- mirt.model(paste("cog = 1-", n_itm_1, sep = ""))
  mdl2 <- mirt.model(paste("cog = 1-", n_itm_2, sep = ""))
  
  
  Theta <- matrix(seq(-4, 4, by = .1))
  
  mcal1 <- mirt(ds[ds$group %in% 1, names(ds) %in% itms1],
                model = mdl1,
                modelitemtype = '2PL',
                pars = pars1)
  mcal2 <- mirt(ds[ds$group %in% 2, names(ds) %in% itms2],
                model = mdl2,
                modelitemtype = '2PL',
                pars = pars2)
  tinfo1 <- testinfo(mcal1, Theta)
  tinfo2 <- testinfo(mcal2, Theta)
  tinfo <- data.frame(cbind(Theta, tinfo1, tinfo2))
  names(tinfo) <- c("ability", "info_1", "info_2")
  
  return(tinfo)
}

# infoCalc is a function that generates test information values for a range of
# abilities based on a mirt results object (mirt_model_obj). It returns a
# dataframe with ability values and corresponding test information values.
# This dataset can be use to graph a test information curve.

infoCalc <- function(mirt_mod_obj) {
  theta <- matrix(seq(-4, 4, by = .1))
  tinfo <- testinfo(mirt_mod_obj, theta)
  tinfo <- data.frame(cbind(theta, tinfo))
  names(tinfo) <- c("ability", "information")
  
  return(tinfo)
}

# summaryStats is a function that calculates means and other performance metrics
# across simulated datasets of summary statistics (rmse, rmse_st, mean, mean_st, sd sd_st)
# returned by equateSim.
#
# Parameters:
#   df - data.frame of summary statistics for each simulated dataset returned
#     by equateSim
#
# summaryStats returns a dataframe with the means across simulated datasets of
# rmse, rmse_st, mean, mean_st, and sd sd_st for each group as well as the
# simple average of both groups. It includes a group variable (Group 1,
# Group 2, Combined)

summaryStats <- function(df) {
  library(tidyverse)
  df$label <- df$statistic
  df$label[df$type == "standardized"] <-
    df$label[df$type == "standardized"] %>%
    paste0(., "_st")
  df$label <- df$label %>%
    gsub("est_", "", ., fixed = TRUE)
  
  sumout <- df %>%
    group_by(group, label) %>%
    summarise(value = mean(avg)) %>%
    pivot_wider(names_from = label, values_from = value)
  
  # Not run: calculate confidence intervals for the means
  # ciM <- df %>%
  #   filter(statistic == "est_mean") %>%
  #   group_by(group, label) %>%
  #   summarise(lowCI = quantile(avg, (1-ci)/2),
  #             upCI = quantile(avg, (1+ci)/2)) %>%
  #   rename_at(c("lowCI", "upCI"), list(~paste0(., 100*ci, "m"))) %>%
  #   pivot_wider(names_from = label, values_from = names(.)[3:4])
  #
  # sumout <- left_join(sumout, ciM, by = "group")
  
  # Calculate the empirical standard error for the means
  ese <- df %>%
    filter(statistic == "est_mean") %>%
    group_by(group, label) %>%
    summarise(ese = sd(avg)) %>%
    pivot_wider(names_from = label, values_from = ese) %>%
    rename(ese = mean, ese_st = mean_st)
  
  sumout <- left_join(sumout, ese, by = "group")
  
  sumout$group <-
    car::recode(sumout$group, '0="Combined"; 1 = "Group 1"; 2 = "Group 2"')
  sumout <- sumout[c(2, 3, 1), ]
  
  # Calculate relative bias in the unstandardized grand means.
  # Constant of 1 added for Group 1, whose population mean is 0.
  sumout$bias <- NA
  for (i in 1:nrow(sumout)) {
    constant <- ifelse(sumout$theta[i] == 0, 1, 0)
    sumout$bias[i] <-
      ((sumout$mean[i] + constant) - (sumout$theta[i] + constant)) / abs(sumout$theta[i] + constant)
  }
  
  # Calculate relative bias in the standardized grand means.
  # Constant of 1 added for Group 1, whose population mean is 0.
  sumout$bias_st <- NA
  for (i in 1:nrow(sumout)) {
    constant <- ifelse(sumout$theta[i] == 0, 1, 0)
    sumout$bias_st[i] <-
      ((sumout$mean_st[i] + constant) - (sumout$theta[i] + constant)) / abs(sumout$theta[i] + constant)
  }
  
  sumout$n_rep <- length(unique(df$samp_num))
  sumout <- sumout %>%
    dplyr::select(
      group,
      theta,
      starts_with("mean"),
      starts_with("sd"),
      starts_with("rmse"),
      starts_with("ese"),
      starts_with("bias"),
      everything()
    )
  
  return(sumout)
  
  
  # rmse_grp_1 <- mean(df[df$group == 1 & df$type == "raw" &
  #                         df$statistic == "rmse","avg"])
  # rmse_grp_2 <- mean(df[df$group == 2 & df$type == "raw" &
  #                         df$statistic == "rmse","avg"])
  # rmse_grp_0 <- mean(df[df$group == 0 & df$type == "raw" &
  #                         df$statistic == "rmse","avg"])
  # rmse_st_grp_1 <- mean(df[df$group == 1 & df$type == "standardized" &
  #                            df$statistic == "rmse","avg"])
  # rmse_st_grp_2 <- mean(df[df$group == 2 & df$type == "standardized" &
  #                            df$statistic == "rmse","avg"])
  # rmse_st_grp_0 <- mean(df[df$group == 0 & df$type == "standardized" &
  #                            df$statistic == "rmse","avg"])
  # mean_grp_1 <- mean(df[df$group == 1 & df$type == "raw" &
  #                         df$statistic == "est_mean","avg"])
  # mean_grp_2 <- mean(df[df$group == 2 & df$type == "raw" &
  #                         df$statistic == "est_mean","avg"])
  # mean_grp_0 <- mean(df[df$group == 0 & df$type == "raw" &
  #                         df$statistic == "est_mean","avg"])
  # mean_st_grp_1 <- mean(df[df$group == 1 & df$type == "standardized" &
  #                            df$statistic == "est_mean","avg"])
  # mean_st_grp_2 <- mean(df[df$group == 2 & df$type == "standardized" &
  #                            df$statistic == "est_mean","avg"])
  # mean_st_grp_0 <- mean(df[df$group == 0 & df$type == "standardized" &
  #                            df$statistic == "est_mean","avg"])
  # sd_grp_1 <- mean(df[df$group == 1 & df$type == "raw" &
  #                       df$statistic == "est_sd","avg"])
  # sd_grp_2 <- mean(df[df$group == 2 & df$type == "raw" &
  #                       df$statistic == "est_sd","avg"])
  # sd_grp_0 <- mean(df[df$group == 0 & df$type == "raw" &
  #                       df$statistic == "est_sd","avg"])
  # sd_st_grp_1 <- mean(df[df$group == 1 & df$type == "standardized" &
  #                          df$statistic == "est_sd","avg"])
  # sd_st_grp_2 <- mean(df[df$group == 2 & df$type == "standardized" &
  #                          df$statistic == "est_sd","avg"])
  # sd_st_grp_0 <- mean(df[df$group == 0 & df$type == "standardized" &
  #                          df$statistic == "est_sd","avg"])
  # # rmse12 <- mean(rmse_grp_1,rmse_grp_2)
  # # rmse_st12 <- mean(rmse_st_grp_1,rmse_st_grp_2)
  # # mean12 <- mean(mean_grp_1,mean_grp_2)
  # # mean_st12 <- mean(mean_st_grp_1,mean_st_grp_2)
  # # sd12 <- mean(sd_grp_1,sd_grp_2)
  # # sd_st12 <- mean(sd_st_grp_1,sd_st_grp_2)
  #
  # nms <- c("rmse","rmse_st","mean","mean_st","sd","sd_st")
  # stat_1 <- data.frame(cbind(rmse_grp_1,rmse_st_grp_1,mean_grp_1,mean_st_grp_1,
  #                            sd_grp_1,sd_st_grp_1))
  # names(stat_1) <- nms
  # stat_1$group <- 1
  # stat_2 <- data.frame(cbind(rmse_grp_2,rmse_st_grp_2,mean_grp_2,mean_st_grp_2,
  #                            sd_grp_2,sd_st_grp_2))
  # names(stat_2) <- nms
  # stat_2$group <- 2
  # stat_12 <- data.frame(cbind(rmse_grp_0,rmse_st_grp_0,mean_grp_0,mean_st_grp_0,
  #                             sd_grp_0,sd_st_grp_0))
  # names(stat_12) <- nms
  # stat_12$group <- 0
  #
  # stat <- rbind(stat_1,stat_2,stat_12)
  # stat$group <- factor(stat$group,levels=c(0,1,2),
  #                      labels=c("Combined","Group 1","Group 2"))
  # return(stat)
}
